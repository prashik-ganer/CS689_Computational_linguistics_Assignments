{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4223ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "#READING FILE\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    contents = file.read()\n",
    "# print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45df9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_vowels = ['अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ']\n",
    "matra = ['ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ो', 'ै', 'ौ', 'ृ', 'ॄ', 'ॉ', 'ं','्','ँ']\n",
    "hindi_consonants = [\n",
    "    'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ',\n",
    "    'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न',\n",
    "    'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श',\n",
    "    'ष', 'स', 'ह', 'ळ', 'क्ष', 'ज्ञ'\n",
    "]\n",
    "mapping = {'ा': 'आ', 'ि': 'इ', 'ी': 'ई', 'ु': 'उ', 'ू': 'ऊ', 'ृ': 'ऋ', 'ॄ': 'ॠ', 'ॅ': 'ऍ', 'े': 'ए', 'ै': 'ऐ', 'ो': 'ओ', 'ौ': 'औ', 'ं': 'अं', 'ः': 'अः', 'ँ': 'अँ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15847596",
   "metadata": {},
   "source": [
    "## FUNCTION FOR FINDING CHARACTERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e851b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Getcharacters(tokens):\n",
    "    characters = []\n",
    "    for word in tokens:\n",
    "        s = []\n",
    "        for ch in word:\n",
    "            if ch==\"▁\" :  continue\n",
    "            if ch == '्' and len(word)==0: continue\n",
    "            elif ch in hindi_vowels: s.append(ch)\n",
    "            elif ch in hindi_consonants:\n",
    "                s.append(ch + '्')\n",
    "                s.append('अ')\n",
    "            elif ch in matra:\n",
    "                if len(s) and s[-1]=='अ': s.pop()\n",
    "                if mapping.get(ch) is not None:\n",
    "                    s.append(mapping.get(ch))\n",
    "        if len(s):\n",
    "              characters.append(s)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ced03",
   "metadata": {},
   "source": [
    "## FUNCTION FOR FINDING SYLLABLES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b9686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get syllables\n",
    "def Getsyllables(tokens):\n",
    "    s = \"\"\n",
    "    syllables = []\n",
    "    for w in tokens:\n",
    "        syllable=[]\n",
    "        s = \"\"\n",
    "        for ch in w:\n",
    "            if ch==\"▁\" :  continue\n",
    "            if ch == '्' and len(s)==0: continue\n",
    "            if ch in hindi_consonants:\n",
    "                if(len(s) and s[-1]!='्'):\n",
    "                    syllable.append(s)\n",
    "                    s = \"\"\n",
    "                s = s + ch\n",
    "            elif ch in hindi_vowels:\n",
    "                s = s + ch\n",
    "                syllable.append(s)\n",
    "                s = \"\"\n",
    "            elif (ch in matra) :\n",
    "                if(len(s) and s[-1] in matra):\n",
    "                    syllable.append(s)\n",
    "                    syllable.append(mapping.get(ch))\n",
    "                    s = \"\"\n",
    "                else: s = s + ch\n",
    "        if len(s):\n",
    "            syllable.append(s) \n",
    "        if len(syllable):\n",
    "            syllables.append(syllable)    \n",
    "    for i in range(0, len(syllables)):\n",
    "        for j in range(0, len(syllables[i])):\n",
    "            if syllables[i][j] in matra:\n",
    "                syllables[i][j] = mapping.get(syllables[i][j])\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e59cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_token(tokens1):\n",
    "    tokens = []\n",
    "    for word in tokens1:\n",
    "        s=\"\"\n",
    "        for c in word:\n",
    "            if (c not in matra) and (c not in hindi_consonants) and (c not in hindi_vowels): continue\n",
    "            else: s = s + c\n",
    "        if(len(s)): tokens.append(s)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a5129",
   "metadata": {},
   "source": [
    "## RANK BY FREQUENCY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f7135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank by frequency\n",
    "def count_ch(ch):\n",
    "    freq = {}\n",
    "    for word in ch:\n",
    "        for c in word:\n",
    "            if c in freq:\n",
    "                freq[c] += 1\n",
    "            else:\n",
    "                freq[c] = 1\n",
    "    sorted_dict = sorted(freq.items(), key=lambda item: item[1], reverse = True)\n",
    "    return sorted_dict[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef53f9",
   "metadata": {},
   "source": [
    "## RANK BY FREQUENCY FOR TOKENS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef58a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank by frequency for tokens\n",
    "def count_t(tokens):\n",
    "    token_freq = {}\n",
    "    for word in tokens:\n",
    "        if word in token_freq:\n",
    "            token_freq[word] += 1\n",
    "        else:\n",
    "            token_freq[word] = 1\n",
    "    sorted_dict = sorted(token_freq.items(), key=lambda item: item[1], reverse = True)\n",
    "    return sorted_dict[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21168baa",
   "metadata": {},
   "source": [
    "## BIGRAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbc808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram\n",
    "def create_bi(lst):\n",
    "    bigram_ch = {}\n",
    "    for word in lst:\n",
    "        for i in range (0, len(word)-1):\n",
    "            if word[i] is None or word[i+1] is None: continue\n",
    "            elif (word[i]+word[i+1]) in bigram_ch:\n",
    "                bigram_ch[word[i]+word[i+1]] += 1\n",
    "            else:\n",
    "                bigram_ch[word[i]+word[i+1]] = 1\n",
    "    bigram_ch = sorted(bigram_ch.items(), key=lambda item: item[1], reverse = True)\n",
    "    return bigram_ch[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71d41a",
   "metadata": {},
   "source": [
    "## BIGRAM FOR TOKENS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee4e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bi_tokens(lst):\n",
    "    bigram_token = {}\n",
    "    for i in range (0, len(lst)-1):\n",
    "        if lst[i] is None or lst[i+1] is None: continue\n",
    "        elif (lst[i]+lst[i+1]) in bigram_token:\n",
    "            bigram_token[lst[i]+lst[i+1]] += 1\n",
    "        else:\n",
    "            bigram_token[lst[i]+lst[i+1]] = 1\n",
    "    bigram_token = sorted(bigram_token.items(), key=lambda item: item[1], reverse = True)\n",
    "    return bigram_token[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161573d5",
   "metadata": {},
   "source": [
    "## FUNCTION FOR FINDING ALL FREQUENCIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d794a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(tokens1):\n",
    "    print(\"GENETRATED TOKENS (TOP 50): \", tokens1[:50])\n",
    "    print(\"\\n\")\n",
    "    ch = Getcharacters(tokens1)\n",
    "#     print(\"UNICODE CORRECTION: \", ch)\n",
    "#     print(\"\\n\")\n",
    "    sy = Getsyllables(tokens1)\n",
    "#     print(\"SYLLABLES: \", sy)\n",
    "#     print(\"\\n\")\n",
    "    T = clean_token(tokens1)\n",
    "#     print(\"CLEANED TOKENS: \", T)\n",
    "#     print(\"\\n\")\n",
    "    count1 = count_ch(ch)\n",
    "    print(\"TOP 20 UNIGRAM CHARACTERS: \", count1)\n",
    "    print(\"\\n\")\n",
    "    count2 = count_ch(sy)\n",
    "    print(\"TOP 20 UNIGRAM SYLLABLES: \", count2)\n",
    "    print(\"\\n\")\n",
    "    count3 = count_t(T)\n",
    "    print(\"TOP 20 UNIGRAM TOKENS:\", count3)\n",
    "    print(\"\\n\")\n",
    "    bi_ch = create_bi(ch)\n",
    "    print(\"TOP 20 BIGRAM CHARACTERS:\", bi_ch)\n",
    "    print(\"\\n\")\n",
    "    bi_syl = create_bi(sy)\n",
    "    print(\"TOP 20 BIGRAM SYLLABLES: \", bi_syl)\n",
    "    print(\"\\n\")\n",
    "    bi_token = create_bi_tokens(T)\n",
    "    print(\"TOP 20 BIGRAM TOKENS: \", bi_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57736e9e",
   "metadata": {},
   "source": [
    "## UNIGRAM TOKENIZER FOR VOCAB_SIZE - 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2077260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_unigram\"\n",
    "vocab_size = 1000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f7a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f\"{model_prefix}.model\")\n",
    "tokens1 = sp.encode_as_pieces(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e2fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIGRAM TOKENIZER: \n",
      "GENETRATED TOKENS (TOP 50):  ['▁आ', 'वे', 'द', 'न', '▁करने', '▁की', '▁आखिर', 'ी', '▁ता', 'री', 'ख', '▁3', '1', '▁जनवरी', ',', '▁20', '20', '▁है', '।', '▁इतन', 'ी', '▁दु', 'आ', '▁कर', '▁दो', '▁हमारे', '▁लिए', '▁कि', '▁ज', 'ित', 'ना', '▁प', '्या', 'र', '▁दुनिया', '▁ने', '▁आपको', '▁दिया', '▁है', ',', '▁ब', 'स', '▁उ', 'त', 'ना', '▁ही', '▁हम', 'ें', '▁भी', '▁मिल']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 9395580), ('आ', 2991109), ('ए', 2318442), ('क्', 2221101), ('र्', 2115631), ('ई', 1460305), ('इ', 1432973), ('न्', 1334418), ('स्', 1283708), ('अं', 1201207), ('ह्', 1133159), ('म्', 1053237), ('त्', 980066), ('ल्', 919917), ('ओ', 896588), ('प्', 805896), ('य्', 753228), ('व्', 624743), ('द्', 607633), ('उ', 587149)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 1295862), ('अं', 1092392), ('क', 682323), ('न', 636034), ('स', 597900), ('इ', 564539), ('आ', 495701), ('प', 466246), ('ए', 458259), ('ल', 455106), ('म', 432836), ('के', 400441), ('त', 397464), ('ह', 351259), ('ने', 323222), ('ब', 301199), ('का', 300427), ('ओ', 298495), ('है', 296118), ('ज', 289541)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('र', 454418), ('के', 349764), ('न', 337967), ('ल', 275778), ('ा', 256523), ('म', 249938), ('में', 240292), ('की', 219786), ('ने', 215783), ('है', 215655), ('क', 214435), ('ी', 211097), ('स', 188105), ('े', 184611), ('का', 184007), ('त', 182961), ('से', 177011), ('प', 169075), ('को', 168166), ('ज', 165639)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 1514714), ('क्अ', 710349), ('न्अ', 648023), ('स्अ', 611390), ('प्अ', 484131), ('अर्', 472306), ('ल्अ', 470130), ('त्अ', 468193), ('म्अ', 462476), ('क्ए', 400441), ('ह्अ', 351259), ('अह्', 344729), ('य्अ', 342979), ('एअं', 332588), ('न्ए', 323222), ('ग्अ', 315013), ('ब्अ', 308189), ('ज्अ', 301505), ('क्आ', 300427), ('ह्ऐ', 296118)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 248182), ('कर', 166933), ('ओअं', 144629), ('और', 115376), ('पर', 112680), ('इस', 105523), ('हैअं', 80463), ('इत', 64108), ('एअं', 62232), ('एक', 58700), ('हीअं', 54284), ('इक', 51667), ('अंग', 47280), ('नही', 47279), ('कार', 43169), ('अप', 39579), ('किया', 36573), ('यह', 35278), ('सम', 33551), ('कहा', 32993)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('केलिए', 43622), ('हैकि', 25724), ('ोंके', 21827), ('रा', 19999), ('ोंमें', 19893), ('केसाथ', 18487), ('री', 18194), ('ार', 17863), ('तेहैं', 17738), ('नेके', 17575), ('ोंको', 16971), ('ताहै', 16258), ('कहाकि', 16116), ('केबाद', 14512), ('रु', 14344), ('ोंकी', 14168), ('नके', 13760), ('ान', 13734), ('नेकहा', 12587), ('रहाहै', 12024)]\n"
     ]
    }
   ],
   "source": [
    "print(\"UNIGRAM TOKENIZER: \")\n",
    "processing(tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b3546",
   "metadata": {},
   "source": [
    "## UNIGRAM TOKENIZER FOR VOCAB_SIZE - 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daed8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_unigram2\"\n",
    "vocab_size = 2000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "399357c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = \"hindi_unigram2\"\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f\"{model_prefix}.model\")\n",
    "tokens1 = sp.encode_as_pieces(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650ab9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIGRAM TOKENIZER FOR VOCAB SIZE 2000: \n",
      "GENETRATED TOKENS (TOP 50):  ['▁आवेदन', '▁करने', '▁की', '▁आखिर', 'ी', '▁तारीख', '▁3', '1', '▁जनवरी', ',', '▁20', '20', '▁है', '।', '▁इतन', 'ी', '▁द', 'ुआ', '▁कर', '▁दो', '▁हमारे', '▁लिए', '▁कि', '▁ज', 'ित', 'ना', '▁प्यार', '▁दुनिया', '▁ने', '▁आपको', '▁दिया', '▁है', ',', '▁बस', '▁उ', 'त', 'ना', '▁ही', '▁हमें', '▁भी', '▁मिल', '▁जाए', '|', '”', '▁मोदी', '▁सरकार', '▁के', '▁पहले', '▁कार्य', 'का']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 8555645), ('आ', 2991109), ('ए', 2318442), ('क्', 2221101), ('र्', 2115631), ('ई', 1460305), ('इ', 1432973), ('न्', 1334418), ('स्', 1283708), ('अं', 1201207), ('ह्', 1133159), ('म्', 1053237), ('त्', 980066), ('ल्', 919917), ('ओ', 896588), ('प्', 805896), ('य्', 753228), ('व्', 624743), ('द्', 607633), ('उ', 587149)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 1164867), ('अं', 1064967), ('क', 663284), ('न', 593532), ('स', 566728), ('प', 432451), ('इ', 416704), ('ल', 413140), ('के', 399027), ('आ', 374444), ('त', 371638), ('म', 361634), ('ए', 330126), ('ह', 329150), ('ने', 321740), ('का', 306198), ('है', 296084), ('मे', 288570), ('ब', 276500), ('ज', 263173)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('के', 334803), ('में', 240292), ('है', 215632), ('की', 207268), ('न', 184136), ('ी', 173237), ('ने', 171964), ('ल', 163999), ('र', 162073), ('को', 161616), ('से', 159035), ('का', 157794), ('क', 151469), ('म', 133013), ('स', 126644), ('ा', 117568), ('और', 115376), ('त', 112119), ('ों', 109310), ('पर', 107520)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 1373877), ('क्अ', 693533), ('अर्', 614289), ('न्अ', 612091), ('स्अ', 581990), ('प्अ', 457498), ('त्अ', 435166), ('ल्अ', 426462), ('क्ए', 399726), ('म्अ', 397280), ('अह्', 359274), ('एअं', 338170), ('ह्अ', 332812), ('न्ए', 321740), ('य्अ', 318558), ('क्आ', 307132), ('आर्', 302100), ('ह्ऐ', 296084), ('य्आ', 291860), ('म्ए', 290675)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 258113), ('कर', 170511), ('ओअं', 125063), ('और', 120831), ('पर', 109465), ('इस', 94381), ('हैअं', 80452), ('एक', 58539), ('हीअं', 54284), ('कार', 49659), ('नही', 49103), ('अप', 44809), ('एअं', 43680), ('अंग', 37409), ('किया', 36573), ('इत', 36026), ('यह', 34020), ('योअं', 33187), ('कहा', 32991), ('इअं', 32266)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('केलिए', 43585), ('हैकि', 25575), ('ोंके', 19374), ('केसाथ', 18448), ('ोंमें', 17805), ('कहाकि', 16110), ('ोंको', 14896), ('केबाद', 14507), ('ोंकी', 12660), ('नेके', 12342), ('नेकहा', 12229), ('रहाहै', 12024), ('हैऔर', 11376), ('गयाहै', 11060), ('ताहै', 10766), ('रहेहैं', 10180), ('करनेके', 8851), ('रहीहै', 8754), ('ोंका', 7873), ('ोंसे', 7849)]\n"
     ]
    }
   ],
   "source": [
    "print(\"UNIGRAM TOKENIZER FOR VOCAB SIZE 2000: \")\n",
    "processing(tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37481abf",
   "metadata": {},
   "source": [
    "## BPE TOKENIZER FOR VOCAB_SIZE -  1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136823e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_bpe\"\n",
    "vocab_size = 1000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05785a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENETRATED TOKENS (TOP 50):  ['▁आ', 'वे', 'दन', '▁करने', '▁की', '▁आ', 'ख', 'ि', 'री', '▁त', 'ारी', 'ख', '▁3', '1', '▁जन', 'व', 'री', ',', '▁20', '2', '0', '▁है', '।', '▁इ', 'त', 'नी', '▁दु', 'आ', '▁कर', '▁दो', '▁हम', 'ारे', '▁लिए', '▁कि', '▁ज', 'ित', 'ना', '▁प', '्य', 'ार', '▁दु', 'निया', '▁ने', '▁आपको', '▁दिया', '▁है', ',', '▁ब', 'स', '▁उ']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 9494781), ('आ', 2991109), ('ए', 2318442), ('क्', 2221101), ('र्', 2115631), ('ई', 1460305), ('इ', 1432973), ('न्', 1334418), ('स्', 1283708), ('अं', 1201207), ('ह्', 1133159), ('म्', 1053237), ('त्', 980066), ('ल्', 919917), ('ओ', 896588), ('प्', 805896), ('य्', 753228), ('व्', 624743), ('द्', 607633), ('उ', 587149)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 1252342), ('अं', 1104660), ('क', 709936), ('आ', 675829), ('इ', 661042), ('न', 607095), ('स', 580344), ('प', 506804), ('म', 479719), ('ल', 461669), ('ए', 426746), ('त', 421137), ('के', 393586), ('ह', 358310), ('ने', 325957), ('ब', 325582), ('ग', 302023), ('ज', 297403), ('है', 296118), ('ओ', 290203)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('के', 364434), ('में', 252765), ('न', 234722), ('की', 227551), ('म', 223876), ('क', 221806), ('है', 215519), ('ने', 209162), ('त', 200426), ('ल', 200164), ('प', 195055), ('स', 187952), ('ज', 182014), ('र', 175155), ('व', 173069), ('से', 171984), ('को', 170953), ('ब', 164575), ('का', 164085), ('द', 158938)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 1442643), ('क्अ', 726024), ('न्अ', 617297), ('स्अ', 595089), ('अर्', 545257), ('म्अ', 512059), ('प्अ', 512024), ('ल्अ', 461669), ('त्अ', 452136), ('क्ए', 393586), ('ह्अ', 362715), ('आर्', 360707), ('एअं', 351357), ('य्अ', 347502), ('ग्अ', 331524), ('न्ए', 325957), ('ब्अ', 325582), ('अह्', 313382), ('व्अ', 304077), ('ज्अ', 301474)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 256824), ('कर', 176032), ('और', 123956), ('ओअं', 117107), ('पर', 112496), ('इस', 95472), ('हैअं', 80599), ('एअं', 79457), ('इक', 67975), ('इत', 66185), ('कार', 60728), ('हीअं', 56185), ('आर', 54901), ('अंग', 54775), ('एक', 54352), ('आन', 50796), ('अप', 47971), ('नही', 47279), ('आल', 45024), ('आय', 43957)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('केलिए', 44395), ('हैकि', 25812), ('केसाथ', 18664), ('ोंके', 18062), ('नेके', 17127), ('कहाकि', 16153), ('ोंमें', 16103), ('तेहैं', 15854), ('केबाद', 15557), ('ोंको', 14304), ('ताहै', 13231), ('नेकहा', 12403), ('रहाहै', 12024), ('ोंकी', 11548), ('हैऔर', 11376), ('गयाहै', 11060), ('रहेहैं', 10182), ('नेकी', 9856), ('वारको', 9235), ('करनेके', 8851)]\n"
     ]
    }
   ],
   "source": [
    "model_prefix = \"hindi_bpe\"\n",
    "sp_b1 = spm.SentencePieceProcessor()\n",
    "sp_b1.load(f\"{model_prefix}.model\")\n",
    "tokens2 = sp_b1.encode_as_pieces(contents)\n",
    "processing(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce6f68",
   "metadata": {},
   "source": [
    "## BPE TOKENIZER FOR VOCAB_SIZE - 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9feec9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_bpe2\"\n",
    "vocab_size = 2000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ed6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE TOKENIZER FOR VOCAB SIZE 2000: \n",
      "GENETRATED TOKENS (TOP 50):  ['▁आ', 'वेदन', '▁करने', '▁की', '▁आख', 'ि', 'री', '▁त', 'ारी', 'ख', '▁3', '1', '▁जनवरी', ',', '▁20', '20', '▁है', '।', '▁इत', 'नी', '▁दु', 'आ', '▁कर', '▁दो', '▁हमारे', '▁लिए', '▁कि', '▁ज', 'ित', 'ना', '▁प', '्य', 'ार', '▁दुनिया', '▁ने', '▁आपको', '▁दिया', '▁है', ',', '▁बस', '▁उ', 'त', 'ना', '▁ही', '▁हमें', '▁भी', '▁मिल', '▁जाए', '|', '”']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 8643728), ('आ', 2991109), ('ए', 2318442), ('क्', 2221101), ('र्', 2115631), ('ई', 1460305), ('इ', 1432973), ('न्', 1334418), ('स्', 1283708), ('अं', 1201207), ('ह्', 1133159), ('म्', 1053237), ('त्', 980066), ('ल्', 919917), ('ओ', 896588), ('प्', 805896), ('य्', 753228), ('व्', 624743), ('द्', 607633), ('उ', 587149)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 1164091), ('अं', 1075390), ('क', 656765), ('न', 576728), ('स', 563096), ('इ', 502138), ('आ', 489918), ('प', 450175), ('ल', 421939), ('के', 402872), ('म', 390011), ('त', 370312), ('ह', 334884), ('ने', 325957), ('का', 304314), ('ए', 301094), ('है', 296118), ('ब', 290766), ('मे', 285742), ('ज', 263570)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('के', 344230), ('में', 245494), ('है', 215519), ('की', 214647), ('ने', 178508), ('को', 164642), ('से', 161960), ('का', 147974), ('क', 135308), ('न', 124503), ('और', 115365), ('म', 114131), ('स', 111941), ('पर', 105525), ('प', 99336), ('ज', 97436), ('व', 96389), ('ल', 95954), ('त', 94389), ('कि', 92995)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 1360453), ('क्अ', 675991), ('अर्', 635321), ('न्अ', 589650), ('स्अ', 579574), ('प्अ', 465789), ('म्अ', 430109), ('ल्अ', 425884), ('त्अ', 409012), ('क्ए', 402872), ('आर्', 366396), ('एअं', 351357), ('अह्', 349873), ('ह्अ', 337544), ('न्ए', 325957), ('य्अ', 325819), ('क्आ', 304314), ('ह्ऐ', 296118), ('ब्अ', 293508), ('ग्अ', 293145)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 259459), ('कर', 169583), ('और', 119313), ('पर', 107325), ('इस', 95508), ('ओअं', 88748), ('हैअं', 80599), ('एअं', 57064), ('हीअं', 56185), ('एक', 54352), ('कार', 51507), ('नही', 49103), ('इत', 46809), ('अप', 46073), ('इक', 45433), ('अंग', 40905), ('आर', 38283), ('योअं', 36742), ('किया', 36546), ('सम', 35035)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('केलिए', 43669), ('हैकि', 25551), ('केसाथ', 18479), ('कहाकि', 16144), ('केबाद', 14525), ('ोंके', 13545), ('ोंमें', 13076), ('नेकहा', 12057), ('रहाहै', 12024), ('नेके', 11995), ('हैऔर', 11376), ('ताहै', 11151), ('गयाहै', 11060), ('रहेहैं', 10182), ('ोंको', 10161), ('करनेके', 8851), ('रहीहै', 8754), ('ोंकी', 8393), ('तेहैं', 8121), ('जाताहै', 7337)]\n"
     ]
    }
   ],
   "source": [
    "model_prefix = \"hindi_bpe2\"\n",
    "sp_b3 = spm.SentencePieceProcessor()\n",
    "sp_b3.load(f\"{model_prefix}.model\")\n",
    "tokens3 = sp_b3.encode_as_pieces(contents)\n",
    "print(\"BPE TOKENIZER FOR VOCAB SIZE 2000: \")\n",
    "processing(tokens3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9346ed6",
   "metadata": {},
   "source": [
    "## mBERT TOKENIZER FOR MAX_LENGTH - 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fe664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned = \"\"\n",
    "# for word in contents:\n",
    "#     s=\"\"\n",
    "#     for c in word:\n",
    "#         if c == ' ': s = s+c\n",
    "#         elif (c not in matra) and (c not in hindi_consonants) and (c not in hindi_vowels): continue\n",
    "#         else: s = s + c\n",
    "#     if(len(s)): cleaned += s\n",
    "# print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "105d0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokens5 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(contents, max_length=1000, truncation=True, padding='max_length')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98bd90d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBERT TOKENIZER FOR VOCAB SIZE 1000: \n",
      "GENETRATED TOKENS (TOP 50):  ['[CLS]', 'आ', '##वे', '##दन', 'करने', 'की', 'आ', '##ख', '##िर', '##ी', 'त', '##ारी', '##ख', '31', 'जनवरी', ',', '2020', 'है', '।', 'इ', '##तन', '##ी', 'दु', '##आ', 'कर', 'दो', 'हम', '##ारे', 'लिए', 'कि', 'ज', '##ित', '##ना', 'प', '##्या', '##र', 'दुनिया', 'ने', 'आ', '##प', '##को', 'दिया', 'है', ',', 'ब', '##स', 'उ', '##तन', '##ा', 'ही']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 658), ('आ', 171), ('क्', 158), ('ए', 147), ('र्', 121), ('इ', 105), ('न्', 84), ('अं', 76), ('स्', 75), ('ई', 72), ('ह्', 71), ('ल्', 67), ('त्', 57), ('ओ', 55), ('म्', 55), ('प्', 55), ('य्', 53), ('ज्', 42), ('व्', 40), ('ऐ', 38)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 88), ('अं', 70), ('क', 61), ('इ', 50), ('न', 46), ('स', 41), ('आ', 39), ('ल', 39), ('प', 36), ('ए', 34), ('ज', 31), ('ब', 30), ('के', 30), ('म', 29), ('य', 25), ('ओ', 24), ('त', 23), ('व', 23), ('है', 23), ('या', 22)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('के', 26), ('प', 20), ('ब', 20), ('में', 20), ('र', 18), ('आ', 16), ('स', 16), ('न', 16), ('है', 15), ('को', 15), ('म', 14), ('ख', 13), ('ी', 12), ('और', 12), ('की', 11), ('ज', 11), ('ा', 11), ('द', 11), ('व', 10), ('ल', 10)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 92), ('क्अ', 62), ('न्अ', 46), ('स्अ', 42), ('ल्अ', 39), ('प्अ', 37), ('अन्', 33), ('अर्', 33), ('ज्अ', 31), ('ब्अ', 30), ('क्ए', 30), ('म्अ', 29), ('य्अ', 27), ('एअं', 25), ('त्अ', 24), ('व्अ', 24), ('ट्अ', 24), ('ह्ऐ', 23), ('द्अ', 22), ('य्आ', 22)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 20), ('कर', 18), ('और', 13), ('अंग', 8), ('इस', 8), ('हैअं', 8), ('ओज', 8), ('ओअं', 7), ('जन', 5), ('एअं', 5), ('इव', 5), ('एक', 5), ('पर', 5), ('इट', 5), ('इल', 4), ('अधि', 4), ('धिक', 4), ('आय', 4), ('ऐअं', 4), ('खेल', 4)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('आप', 7), ('खोज', 7), ('हैकि', 4), ('ोजशब्द', 4), ('ोंकी', 3), ('्प', 3), ('कोब', 3), ('आयरल', 3), ('रलैंड', 3), ('विके', 3), ('ब्रा', 3), ('्रायन', 3), ('केलिए', 3), ('शब्दों', 3), ('आकर', 2), ('जित', 2), ('ितना', 2), ('पको', 2), ('दियाहै', 2), ('उतन', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(\"mBERT TOKENIZER FOR VOCAB SIZE 1000: \")\n",
    "processing(tokens5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc716d3c",
   "metadata": {},
   "source": [
    "## mBERT TOKENIZER FOR MAX_LENGTH - 2000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64cef9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokens6 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(contents, max_length=2000, truncation=True, padding='max_length')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d9932c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBERT TOKENIZER FOR VOCAB SIZE 2000: \n",
      "GENETRATED TOKENS (TOP 50):  ['[CLS]', 'आ', '##वे', '##दन', 'करने', 'की', 'आ', '##ख', '##िर', '##ी', 'त', '##ारी', '##ख', '31', 'जनवरी', ',', '2020', 'है', '।', 'इ', '##तन', '##ी', 'दु', '##आ', 'कर', 'दो', 'हम', '##ारे', 'लिए', 'कि', 'ज', '##ित', '##ना', 'प', '##्या', '##र', 'दुनिया', 'ने', 'आ', '##प', '##को', 'दिया', 'है', ',', 'ब', '##स', 'उ', '##तन', '##ा', 'ही']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 1277), ('आ', 349), ('क्', 292), ('ए', 285), ('र्', 248), ('इ', 208), ('ई', 168), ('न्', 166), ('स्', 156), ('अं', 141), ('ह्', 131), ('म्', 123), ('ल्', 119), ('त्', 109), ('य्', 109), ('ओ', 106), ('प्', 99), ('व्', 81), ('ज्', 79), ('द्', 72)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 187), ('अं', 131), ('क', 105), ('इ', 98), ('स', 88), ('आ', 85), ('न', 83), ('प', 72), ('ए', 60), ('ल', 60), ('म', 59), ('ज', 54), ('ब', 52), ('व', 50), ('य', 49), ('उ', 47), ('ट', 47), ('ने', 45), ('है', 44), ('के', 44)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('र', 38), ('के', 38), ('स', 37), ('में', 37), ('म', 35), ('प', 34), ('ब', 34), ('की', 29), ('है', 29), ('न', 28), ('ज', 27), ('ने', 27), ('ी', 23), ('आ', 22), ('ा', 22), ('को', 21), ('और', 21), ('व', 20), ('का', 18), ('द', 17)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 193), ('क्अ', 106), ('स्अ', 89), ('न्अ', 83), ('प्अ', 73), ('अर्', 66), ('म्अ', 60), ('ल्अ', 60), ('य्अ', 55), ('ट्अ', 55), ('ज्अ', 54), ('ब्अ', 53), ('व्अ', 51), ('त्अ', 50), ('अन्', 48), ('एअं', 46), ('न्ए', 45), ('ह्ऐ', 44), ('क्ए', 44), ('द्अ', 43)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 38), ('कर', 24), ('और', 22), ('इस', 18), ('हैअं', 15), ('एक', 13), ('पर', 13), ('ओअं', 12), ('कार', 10), ('अंग', 9), ('अधि', 8), ('इट', 8), ('ओज', 8), ('एअं', 7), ('आय', 7), ('आर', 7), ('दिया', 6), ('धिक', 6), ('ऐअं', 6), ('अंड', 6)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('आप', 7), ('खोज', 7), ('हैकि', 5), ('केलिए', 5), ('जर', 5), ('स्व', 4), ('ोजशब्द', 4), ('नेकहा', 4), ('टॉ', 4), ('ॉय', 4), ('यले', 4), ('लेट', 4), ('नेता', 3), ('सच', 3), ('ोंकी', 3), ('सम', 3), ('्प', 3), ('पक्ष', 3), ('कोब', 3), ('बढ', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(\"mBERT TOKENIZER FOR VOCAB SIZE 2000: \")\n",
    "processing(tokens6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d665b12",
   "metadata": {},
   "source": [
    "## Indic-BERT TOKENIZER (MAX-LENGTH-1000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokens7 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=1000, truncation=True)))\n",
    "# print(tokens7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indic-BERT TOKENIZER FOR 1000: \")\n",
    "processing(tokens7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6a260",
   "metadata": {},
   "source": [
    "## Indic-BERT TOKENIZER (MAX-LENGTH-2000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "tokens9 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=2000, truncation=True)))\n",
    "# print(tokens7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Indic-BERT TOKENIZER FOR 2000: \")\n",
    "processing(tokens9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4e54",
   "metadata": {},
   "source": [
    "## WHITE SPACE TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87907c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE SPACE TOKENIZER: \n",
      "GENETRATED TOKENS (TOP 50):  ['आवेदन', 'करने', 'की', 'आखिरी', 'तारीख', '31', 'जनवरी,', '2020', 'है।', 'इतनी', 'दुआ', 'कर', 'दो', 'हमारे', 'लिए', 'कि', 'जितना', 'प्यार', 'दुनिया', 'ने', 'आपको', 'दिया', 'है,', 'बस', 'उतना', 'ही', 'हमें', 'भी', 'मिल', 'जाए|”', 'मोदी', 'सरकार', 'के', 'पहले', 'कार्यकाल', 'में', 'भी', 'तीन', 'तलाक', 'को', 'लेकर', 'बिल', 'लाया', 'गया', 'था,', 'हालांकि', 'तब', 'यह', 'राज्यसभा', 'में']\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM CHARACTERS:  [('अ', 7012291), ('आ', 2991109), ('ए', 2318442), ('क्', 2219964), ('र्', 2115649), ('ई', 1460305), ('इ', 1432973), ('न्', 1334448), ('स्', 1283708), ('अं', 1201207), ('ह्', 1133159), ('म्', 1053237), ('त्', 980066), ('ल्', 919917), ('ओ', 896588), ('प्', 805896), ('य्', 752819), ('व्', 624743), ('द्', 607633), ('उ', 587149)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM SYLLABLES:  [('र', 1002121), ('अं', 989071), ('क', 584168), ('न', 493166), ('स', 483272), ('के', 404884), ('प', 382596), ('ने', 327692), ('ल', 323888), ('त', 307274), ('का', 304973), ('है', 296441), ('मे', 292632), ('म', 287396), ('ह', 278181), ('अ', 246469), ('की', 235714), ('ब', 235290), ('या', 222200), ('से', 214070)]\n",
      "\n",
      "\n",
      "TOP 20 UNIGRAM TOKENS: [('के', 317077), ('में', 239719), ('है', 210965), ('की', 195499), ('को', 145820), ('से', 138030), ('और', 114890), ('का', 110464), ('ने', 102677), ('पर', 89373), ('हैं', 79549), ('कि', 77523), ('भी', 64731), ('एक', 49798), ('लिए', 49285), ('इस', 47867), ('नहीं', 47245), ('कर', 44846), ('ही', 40557), ('किया', 36489)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM CHARACTERS: [('र्अ', 1169786), ('अर्', 785450), ('क्अ', 608087), ('स्अ', 517717), ('न्अ', 514986), ('अन्', 432259), ('क्ए', 407506), ('प्अ', 401005), ('अह्', 390462), ('आर्', 368751), ('एअं', 359416), ('त्अ', 353927), ('अक्', 350898), ('न्ए', 328985), ('ल्अ', 328835), ('म्अ', 322649), ('क्आ', 315162), ('अत्', 308135), ('य्आ', 297809), ('ह्ऐ', 297203)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM SYLLABLES:  [('मेअं', 259204), ('कर', 159758), ('और', 115449), ('पर', 99620), ('इस', 81541), ('हैअं', 80719), ('हीअं', 55607), ('एक', 53344), ('नही', 49370), ('अप', 43968), ('कार', 38877), ('किया', 37475), ('योअं', 34603), ('रने', 34497), ('कहा', 33097), ('यह', 31401), ('गया', 30261), ('सर', 30070), ('आप', 28728), ('साथ', 27724)]\n",
      "\n",
      "\n",
      "TOP 20 BIGRAM TOKENS:  [('केलिए', 43451), ('हैकि', 25153), ('केसाथ', 17431), ('कहाकि', 16094), ('केबाद', 14373), ('रहाहै', 11948), ('नेकहा', 11696), ('हैऔर', 11372), ('गयाहै', 10979), ('रहेहैं', 10116), ('करनेके', 8846), ('रहीहै', 8699), ('जाताहै', 7260), ('कियागया', 6879), ('सकताहै', 6473), ('नहींहै', 6466), ('बतायाकि', 6450), ('कियाहै', 6176), ('होताहै', 6166), ('करदिया', 6071)]\n"
     ]
    }
   ],
   "source": [
    "tokens8 = contents.split()\n",
    "print(\"WHITE SPACE TOKENIZER: \")\n",
    "processing(tokens8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be769e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
