{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afa5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clq5.txt', 'r', encoding='utf-8') as file:\n",
    "    contents = file.read()\n",
    "# print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c332089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_vowels = ['अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ']\n",
    "matra = ['ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ो', 'ै', 'ौ', 'ृ', 'ॄ', 'ॉ', 'ं','्','ँ']\n",
    "hindi_consonants = [\n",
    "    'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ',\n",
    "    'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न',\n",
    "    'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श',\n",
    "    'ष', 'स', 'ह', 'ळ', 'क्ष', 'ज्ञ'\n",
    "]\n",
    "mapping = {'ा': 'आ', 'ि': 'इ', 'ी': 'ई', 'ु': 'उ', 'ू': 'ऊ', 'ृ': 'ऋ', 'ॄ': 'ॠ', 'ॅ': 'ऍ', 'े': 'ए', 'ै': 'ऐ', 'ो': 'ओ', 'ौ': 'औ', 'ं': 'अं', 'ः': 'अः', 'ँ': 'अँ'}\n",
    "def clean_token(tokens1):\n",
    "    tokens = []\n",
    "    for word in tokens1:\n",
    "        s=\"\"\n",
    "        for c in word:\n",
    "            if (c not in matra) and (c not in hindi_consonants) and (c not in hindi_vowels): continue\n",
    "            else: s = s + c\n",
    "        if(len(s)): tokens.append(s)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802b369",
   "metadata": {},
   "source": [
    "# TOKENIZATION MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d34903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cde83",
   "metadata": {},
   "source": [
    "## UNIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e0d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_unigram\"\n",
    "vocab_size = 1000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='unigram')\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f\"{model_prefix}.model\")\n",
    "def unigram_model(sen):\n",
    "    tokens1 = sp.encode_as_pieces(sen)\n",
    "    return tokens1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a623642",
   "metadata": {},
   "source": [
    "## BPE MODEL (VOCAB_SIZE : 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f3197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_bpe\"\n",
    "vocab_size = 1000 \n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='bpe')\n",
    "sp_b1 = spm.SentencePieceProcessor()\n",
    "sp_b1.load(f\"{model_prefix}.model\")\n",
    "def bpe_1000(sen):\n",
    "    tokens2 = sp_b1.encode_as_pieces(sen)\n",
    "    return tokens2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabacb8",
   "metadata": {},
   "source": [
    "## BPE MODEL (VOCAB_SIZE : 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788e20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"hi_100.txt\"\n",
    "model_prefix = \"hindi_bpe2\"\n",
    "vocab_size = 2000\n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type='bpe')\n",
    "sp_b1 = spm.SentencePieceProcessor()\n",
    "sp_b1.load(f\"{model_prefix}.model\")\n",
    "def bpe_2000(sen):\n",
    "    tokens3 = sp_b1.encode_as_pieces(sen)\n",
    "    return tokens3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f890e6a3",
   "metadata": {},
   "source": [
    "## m-BERT  (MAX-LENGTH:1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3544ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "def mbert_m(sen):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokens4 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=1000, truncation=True, padding='max_length')))\n",
    "    return tokens4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d9079",
   "metadata": {},
   "source": [
    "## m-BERT  (MAX-LENGTH:2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bdb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "def mbert_m2(sen):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    tokens5 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=2000, truncation=True, padding='max_length')))\n",
    "    return tokens5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c60c1e",
   "metadata": {},
   "source": [
    "## Indic-BERT (MAX-LENGTH:1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd31e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "def indicbert(sen):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "    tokens6 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=1000, truncation=True)))\n",
    "    return tokens6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912b20a",
   "metadata": {},
   "source": [
    "## Indic-BERT (MAX-LENGTH:2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6289ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "def indicbert2(sen):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "    tokens7 = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sen, max_length=1000, truncation=True)))\n",
    "    return tokens7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f85a9",
   "metadata": {},
   "source": [
    "## WHITE SPACE TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a291b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_space(sen):\n",
    "    tokens8 = contents.split()\n",
    "    return tokens8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb490a91",
   "metadata": {},
   "source": [
    "## FUNCTION FOR CALCULATION OF PRECISION, RECALL, F-SCORE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6362451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cal(ground_truth, tokenizer_output):\n",
    "    true_positives = 0.0\n",
    "    false_positives = 0.0\n",
    "    false_negatives = 0.0\n",
    "    for i in range(0, len(ground_truth)):\n",
    "        true_positives += len(set(ground_truth[i]) & set(tokenizer_output[i]))\n",
    "        false_positives += len(set(tokenizer_output[i]) - set(ground_truth[i]))\n",
    "        false_negatives += len(set(ground_truth[i]) - set(tokenizer_output[i]))\n",
    "    if (true_positives + false_positives) != 0: precision = true_positives / (true_positives + false_positives)\n",
    "    else : precision = 0\n",
    "    if (true_positives + false_negatives) != 0: recall = true_positives / (true_positives + false_negatives)\n",
    "    else : recall = 0\n",
    "    if (precision + recall) != 0: f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else : f_score = 0\n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e7c74",
   "metadata": {},
   "source": [
    "## SOLUTION OF WORD-GROUPS FROM QUES-3 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e307ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = [['नगर पालिका कर्मचारी संघ', 'हरियाणा के', 'आह्वïान पर', 'आज यहां', 'नगर निगम के कर्मचारियों ने', 'जिला प्रधान धर्मवीर सारसर की', 'अध्यक्षता में', 'मांगों के समर्थन', 'में भूख हड़ताल की'], \n",
    "['आपको', 'अलग-अलग परीक्षण करना', 'चाहिए', 'और', 'खोजशब्द शोधकर्ताओं को', 'अपनी सूची में', 'सबसे अधिक प्रासंगिक और लक्षित खोज शब्दों को', 'खोजने के लिए', 'प्रदान करना चाहिए'], \n",
    "['मोका कारवाईंतर्गंत', 'म्होरक्यासह', '97 गुंडांना', 'झटका'], \n",
    "['अमेज़न और फ्लिपकार्ट', 'को टक्कर देगा', 'ई-कॉमर्स पोर्टल GeM'],\n",
    "['उम्मीद है', 'कि यह बिजली संयंत्र', '6 से 9 महीने में', 'लग जाएगा', 'और', 'कम से कम 15 साल तक', 'चलेगा'],\n",
    "['घायल हुए', 'इस स्वर्ण व्यवसायी की', 'पहचान', 'जिला के सैदपुरा के', 'रहने वाले', '50 वर्षीय राज किशोर साह', 'के रूप में', 'की गयी है', 'जो', 'काजीमोहम्मद पुर थाना क्षेत्र के', 'सतपुरा इलाके के', 'निवासी', 'थे', 'और', 'घटना के वक्त', 'अपने छोटे बेटे के साथ', 'दुकान बंद कर घर वापस लौट रहे थे'], \n",
    "['सरकार ने', 'विभिन्न खेलों के', 'इन खिलाडिय़ों में से', 'चार को', 'सीधे पुलिस उपाधीक्षक (डीएसपी)', '18 को', 'निरीक्षक (इंस्पेक्टर)', 'तथा', '14 को', 'उप-निरीक्षक (सब-इंस्पेक्टर)', 'नियुक्त किया है'], ['दौर सराफा में', 'Gold', '40,080 रुपए प्रति 10 ग्राम', 'बिका'], \n",
    "['इस ट्रायल में', 'शामिल रहे', 'एक वरिष्ठ वैज्ञानिक डॉक्टर आरएस शर्मा', 'का कहना है', 'कि यह इंजेक्शन पूरी तरह तैयार है', 'केवल ड्रग कंट्रोलर से', 'इसकी अनुमति लिया जाना बाक़ी है'], \n",
    "['घर में', 'शुभ प्रसंग', 'का', 'आयोजन हो सकता है'], \n",
    "['हितग्राही को', 'यह जरूर', 'महसूस होना चाहिए', 'कि मुझे जो सहायता मिल रही है', 'वह खैरात नहीं है', 'बल्कि मेरी लियाकत की वजह से है', 'मेरी मेहनत के फलस्वरूप है'], ['आरबीआई ने', 'मामले की', 'जांच शुरू कर दी है'], \n",
    "['जिनका', 'जिक्र', 'अंग्रेजी के', 'शब्दकोश में', 'है ही नहीं'], \n",
    "['बेशक', 'प्रधानमंत्री डॉ. मनमोहन सिंह', 'यह मानें', 'कि इससे देश की बदनामी होती है'], \n",
    "['विद्यार्थियों को', 'कंप्यूटर की सॉफ्टवेयर व हार्डवेयर की हर प्रकार की', 'जानकारी होना आवश्यक है', 'और सीखने आए विद्यार्थियों ने', 'कहा', 'कि यह जानकारी उनके लिए अच्छी है'], ['बाद में', 'भास्कर के जीएम कमल शर्मा', 'वकील के साथ', 'थाने गए', 'और', 'पालना का', 'आश्वसन देकर', 'आए'], \n",
    "['बैठक के बाद से', 'मीडिया में', 'कयास लगाए जाने लगे थे', 'कि जम्मू-कश्मीर पर', 'केंद्र सरकार ने', 'कोई बड़ा फैसला', 'ले लिया है'], \n",
    "['नारायण साईं पर', 'जेल में रहते हुए', 'पुलिस कर्मचारी को', '13 करोड़ रुपए की', 'रिश्वत देने का', 'भी आरोप लगा था', 'लेकिन इस मामले में', 'नारायण साईं को', 'जमानत तो मिल चुकी है', 'लेकिन रेप के मामले में', 'अभी भी', 'कोर्ट में', 'सुनवाई चल रही है'], \n",
    "['इस बार', '10वीं में', '34,04,471', 'और', '12वीं में', '26,24,681', 'यानि', 'कुल', '60,29,152 लाख', 'रेगुलर और प्राइवेट विद्यार्थियों', 'ने', 'भाग लिया था'], ['और जब', 'वो पानी से', 'निकल कर', 'ऊपर आया', 'तो फ़ौरन', 'उसने', 'आसमान को', 'खुलते और रूह को', 'कबूतर की तरह', 'अपने ऊपर आते', 'देखा'], ['उस ताम्बे की परत पे', 'जमे परतों के', 'जो रंग हैं'], \n",
    "['मार्सिलिया (Marsilea) तथा सिरेटोप्टेरिस (Ceratopteris)', 'जैसे', 'टेरिडोफाइट्स का', 'उपयोग', 'सब्जी के रूप में', 'होता है'], ['लेकिन अब', 'उनके डांस का', 'वीडियो', 'वायरल होने के बाद', 'तो उनकी लॉटरी लग गई है'], \n",
    "['इस दौरान', 'मारा मार्टिन ने', 'स्वीमशूट पहना हुआ है', 'वीडियो में', 'साफ नजर आ रहा है', 'कि जब मारा मार्टिन', 'रैंफ वॉक कर रही हैं', 'तो वहां मौजूद लोग', 'जमकर उनके लिए', 'तालियां बजा रहे हैं'], \n",
    "['तीन बच्चों की', 'मां', 'बियोंसे का', 'मानना है', 'कि स्तनपान', 'बच्चे को', 'जन्म देने के बाद', 'वजन घटाने का', 'सबसे कारगर और स्वस्थ तरीका है']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061719bf",
   "metadata": {},
   "source": [
    "## TOKENIZE ON UNIGRAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225c034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = contents.split(\"\\n\")\n",
    "lst_lines = []\n",
    "for sentence in lines:\n",
    "    token = unigram_model(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_lines.append(ctoken)\n",
    "# print(lst_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f55e2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Tokenizer Metrics:\n",
      "Precision:  0.021170610211706103\n",
      "Recall:  0.09239130434782608\n",
      "F-score:  0.034447821681864235\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_lines)\n",
    "print(\"Unigram Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fad55f",
   "metadata": {},
   "source": [
    "## TOKENIZE ON BPE FOR VOCAB_SIZE 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8a1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesb = []\n",
    "for sentence in lines:\n",
    "    token = bpe_1000(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesb.append(ctoken)\n",
    "# print(lst_linesb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d40db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram - 1000 Tokenizer Metrics:\n",
      "Precision:  0.02981029810298103\n",
      "Recall:  0.11956521739130435\n",
      "F-score:  0.047722342733188726\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesb)\n",
    "print(\"Bigram - 1000 Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1e29b",
   "metadata": {},
   "source": [
    "## TOKENIZE ON BPE FOR VOCAB_SIZE 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91843ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesb2 = []\n",
    "for sentence in lines:\n",
    "    token = bpe_2000(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesb2.append(ctoken)\n",
    "# print(lst_linesb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b402660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram - 2000 Tokenizer Metrics:\n",
      "Precision:  0.02981029810298103\n",
      "Recall:  0.11956521739130435\n",
      "F-score:  0.047722342733188726\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesb2)\n",
    "print(\"Bigram - 2000 Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a2ef7",
   "metadata": {},
   "source": [
    "## TOKENIZE ON mBERT - 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18be9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesm = []\n",
    "for sentence in lines:\n",
    "    token = mbert_m(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesm.append(ctoken)\n",
    "# print(lst_linesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1990313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBERT Tokenizer Metrics:\n",
      "Precision:  0.020531400966183576\n",
      "Recall:  0.09239130434782608\n",
      "F-score:  0.03359683794466403\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesm)\n",
    "print(\"mBERT Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109145bc",
   "metadata": {},
   "source": [
    "## TOKENIZE ON mBERT - 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b20a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesm2 = []\n",
    "for sentence in lines:\n",
    "    token = mbert_m2(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesm2.append(ctoken)\n",
    "# print(lst_linesm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "695354d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mBERT Tokenizer Metrics:\n",
      "Precision:  0.020531400966183576\n",
      "Recall:  0.09239130434782608\n",
      "F-score:  0.03359683794466403\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesm2)\n",
    "print(\"mBERT Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fa3ea",
   "metadata": {},
   "source": [
    "## TOKENIZE ON INDIC-BERT - 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d922b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesi = []\n",
    "for sentence in lines:\n",
    "    token = indicbert(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesi.append(ctoken)\n",
    "# print(lst_linesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aec18e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indic BERT Tokenizer Metrics:\n",
      "Precision:  0.009917355371900827\n",
      "Recall:  0.03260869565217391\n",
      "F-score:  0.015209125475285173\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesi)\n",
    "print(\"Indic BERT Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce317a5",
   "metadata": {},
   "source": [
    "## TOKENIZE ON INDIC-BERT - 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5df241f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_linesi2 = []\n",
    "for sentence in lines:\n",
    "    token = indicbert2(sentence)\n",
    "    ctoken = clean_token(token)\n",
    "    lst_linesi2.append(ctoken)\n",
    "# print(lst_linesi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "641a7a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indic BERT Tokenizer Metrics:\n",
      "Precision:  0.009917355371900827\n",
      "Recall:  0.03260869565217391\n",
      "F-score:  0.015209125475285173\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesi)\n",
    "print(\"Indic BERT Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5ae68",
   "metadata": {},
   "source": [
    "## TOKENIZE ON WHITE-SPACE TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7558bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['नगर', 'पालिका', 'कर्मचारी', 'संघ', 'हरियाणा', 'के', 'आह्वïान', 'पर', 'आज', 'यहां', 'नगर', 'निगम', 'के', 'कर्मचारियों', 'ने', 'जिला', 'प्रधान', 'धर्मवीर', 'सारसर', 'की', 'अध्यक्षता', 'में', 'मांगों', 'के', 'समर्थन', 'में', 'भूख', 'हड़ताल', 'की।'], ['आपको', 'अलग-अलग', 'परीक्षण', 'करना', 'चाहिए', 'और', 'खोजशब्द', 'शोधकर्ताओं', 'को', 'अपनी', 'सूची', 'में', 'सबसे', 'अधिक', 'प्रासंगिक', 'और', 'लक्षित', 'खोज', 'शब्दों', 'को', 'खोजने', 'के', 'लिए', 'प्रदान', 'करना', 'चाहिए।', ''], ['मोका', 'कारवाईंतर्गंत\\xa0म्होरक्यासह', '97', 'गुंडांना', 'झटका'], ['अमेज़न', 'और', 'फ्लिपकार्ट', 'को', 'टक्कर', 'देगा', 'ई-कॉमर्स', 'पोर्टल', 'GeM'], ['उम्मीद', 'है', 'कि', 'यह', 'बिजली', 'संयंत्र', '6', 'से', '9', 'महीने', 'में', 'लग', 'जाएगा', 'और', 'कम', 'से', 'कम', '15', 'साल', 'तक', 'चलेगा।'], ['घायल', 'हुए', 'इस', 'स्वर्ण', 'व्यवसायी', 'की', 'पहचान', 'जिला', 'के', 'सैदपुरा', 'के', 'रहने', 'वाले', '50', 'वर्षीय', 'राज', 'किशोर', 'साह', 'के', 'रूप', 'में', 'की', 'गयी', 'है', 'जो', 'काजीमोहम्मद', 'पुर', 'थाना', 'क्षेत्र', 'के', 'सतपुरा', 'इलाके', 'के', 'निवासी', 'थे', 'और', 'घटना', 'के', 'वक्त', 'अपने', 'छोटे', 'बेटे', 'के', 'साथ', 'दुकान', 'बंद', 'कर', 'घर', 'वापस', 'लौट', 'रहे', 'थे.'], ['सरकार', 'ने', 'विभिन्न', 'खेलों', 'के', 'इन', 'खिलाडिय़ों', 'में', 'से', 'चार', 'को', 'सीधे', 'पुलिस', 'उपाधीक्षक', '(डीएसपी),', '18', 'को', 'निरीक्षक', '(इंस्पेक्टर)', 'तथा', '14', 'को', 'उप-निरीक्षक', '(सब-इंस्पेक्टर)', 'नियुक्त', 'किया', 'है।'], ['इंदौर', 'सराफा', 'में', 'Gold', '40,080', 'रुपए', 'प्रति', '10', 'ग्राम', 'बिका।'], ['इस', 'ट्रायल', 'में', 'शामिल', 'रहे', 'एक', 'वरिष्ठ', 'वैज्ञानिक', 'डॉक्टर', 'आरएस', 'शर्मा', 'का', 'कहना', 'है', 'कि', 'यह', 'इंजेक्शन', 'पूरी', 'तरह', 'तैयार', 'है,', 'केवल', 'ड्रग', 'कंट्रोलर', 'से', 'इसकी', 'अनुमति', 'लिया', 'जाना', 'बाक़ी', 'है.'], ['घर', 'में', 'शुभ', 'प्रसंग', 'का', 'आयोजन', 'हो', 'सकता', 'है।'], ['हितग्राही', 'को', 'यह', 'जरूर', 'महसूस', 'होना', 'चाहिए', 'कि', 'मुझे', 'जो', 'सहायता', 'मिल', 'रही', 'है', 'वह', 'खैरात', 'नहीं', 'है', 'बल्कि', 'मेरी', 'लियाकत', 'की', 'वजह', 'से', 'है.', 'मेरी', 'मेहनत', 'के', 'फलस्वरूप', 'है।', ''], ['आरबीआई', 'ने', 'मामले', 'की', 'जांच', 'शुरू', 'कर', 'दी', 'है।'], ['जिनका', 'जिक्र', 'अंग्रेजी', 'के', 'शब्दकोश', 'में', 'है', 'ही', 'नहीं।'], ['बेशक', 'प्रधानमंत्री', 'डॉ.', 'मनमोहन', 'सिंह', 'यह', 'मानें', 'कि', 'इससे', 'देश', 'की', 'बदनामी', 'होती', 'है।'], ['विद्यार्थियों', 'को', 'कंप्यूटर', 'की', 'सॉफ्टवेयर', 'व', 'हार्डवेयर', 'की', 'हर', 'प्रकार', 'की', 'जानकारी', 'होना', 'आवश्यक', 'है', 'और', 'सीखने', 'आए', 'विद्यार्थियों', 'ने', 'कहा', 'कि', 'यह', 'जानकारी', 'उनके', 'लिए', 'अच्छी', 'है।'], ['बाद', 'में', 'भास्कर', 'के', 'जीएम', 'कमल', 'शर्मा', 'वकील', 'के', 'साथ', 'थाने', 'गए', 'और', 'पालना', 'का', 'आश्वसन', 'देकर', 'आए।'], ['बैठक', 'के', 'बाद', 'से', 'मीडिया', 'में', 'कयास', 'लगाए', 'जाने', 'लगे', 'थे', 'कि', 'जम्मू-कश्मीर', 'पर', 'केंद्र', 'सरकार', 'ने', 'कोई', 'बड़ा', 'फैसला', 'ले', 'लिया', 'है।'], ['नारायण', 'साईं', 'पर', 'जेल', 'में', 'रहते', 'हुए', 'पुलिस', 'कर्मचारी', 'को', '13', 'करोड़', 'रुपए', 'की', 'रिश्वत', 'देने', 'का', 'भी', 'आरोप', 'लगा', 'था,', 'लेकिन', 'इस', 'मामले', 'में', 'नारायण', 'साईं', 'को', 'जमानत', 'तो', 'मिल', 'चुकी', 'है', 'लेकिन', 'रेप', 'के', 'मामले', 'में', 'अभी', 'भी', 'कोर्ट', 'में', 'सुनवाई', 'चल', 'रही', 'है।'], ['इस', 'बार', '10वीं', 'में', '34,04,471', 'और', '12वीं', 'में', '26,24,681', 'यानि', 'कुल', '60,29,152', 'लाख', 'रेगुलर', 'और', 'प्राइवेट', 'विद्यार्थियों', 'ने', 'भाग', 'लिया', 'था।'], ['और', 'जब', 'वो', 'पानी', 'से', 'निकल', 'कर', 'ऊपर', 'आया', 'तो', 'फ़ौरन', 'उसने', 'आसमान', 'को', 'खुलते', 'और', 'रूह', 'को', 'कबूतर', 'की', 'तरह', 'अपने', 'ऊपर', 'आते', 'देखा।'], ['उस', 'ताम्बे', 'की', 'परत', 'पे', 'जमे', 'परतों', 'के', 'जो', 'रंग', 'हैं,'], ['मार्सिलिया', '(Marsilea)', 'तथा', 'सिरेटोप्टेरिस', '(Ceratopteris)', 'जैसे', 'टेरिडोफाइट्स', 'का', 'उपयोग', 'सब्जी', 'के', 'रूप', 'में', 'होता', 'है।'], ['लेकिन', 'अब', 'उनके', 'डांस', 'का', 'वीडियो', 'वायरल', 'होने', 'के', 'बाद', 'तो', 'उनकी', 'लॉटरी', 'लग', 'गई', 'है', '।'], ['इस', 'दौरान', 'मारा', 'मार्टिन', 'ने', 'स्वीमशूट', 'पहना', 'हुआ', 'है।', 'वीडियो', 'में', 'साफ', 'नजर', 'आ', 'रहा', 'है', 'कि', 'जब', 'मारा', 'मार्टिन', 'रैंफ', 'वॉक', 'कर', 'रही', 'हैं', 'तो', 'वहां', 'मौजूद', 'लोग', 'जमकर', 'उनके', 'लिए', 'तालियां', 'बजा', 'रहे', 'हैं।'], ['तीन', 'बच्चों', 'की', 'मां', 'बियोंसे', 'का', 'मानना', 'है', 'कि', 'स्तनपान', 'बच्चे', 'को', 'जन्म', 'देने', 'के', 'बाद', 'वजन', 'घटाने', 'का', 'सबसे', 'कारगर', 'और', 'स्वस्थ', 'तरीका', 'है।']]\n"
     ]
    }
   ],
   "source": [
    "lines = contents.split(\"\\n\")\n",
    "lst_linesw = []\n",
    "for sentence in lines:\n",
    "    token = sentence.split(\" \")\n",
    "    lst_linesw.append(token)\n",
    "print(lst_linesw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47fd6459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Space Tokenizer Metrics:\n",
      "Precision:  0.05731225296442688\n",
      "Recall:  0.15760869565217392\n",
      "F-score:  0.08405797101449276\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_score = score_cal(gt,  lst_linesw)\n",
    "print(\"White Space Tokenizer Metrics:\")\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F-score: \",f_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
