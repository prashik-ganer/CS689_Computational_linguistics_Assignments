{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8138765,"sourceType":"datasetVersion","datasetId":4811618}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CHATGPT TRANSLATIONS","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/chatgptfiles/enselected.txt', 'r') as f1:\n    en = f1.readlines()\n\nwith open('/kaggle/input/chatgptfiles/hiselected.txt', 'r') as f2:\n    hi = f2.readlines()\n\nwith open('/kaggle/input/chatgptfiles/taselected.txt', 'r') as f2:\n    ta = f2.readlines()\n    \nwith open('/kaggle/input/chatgptfiles/en_to_hi.txt', 'r') as f1:\n    en_to_hi = f1.readlines()\n    \nwith open('/kaggle/input/chatgptfiles/hi_to_en.txt', 'r') as f1:\n    hi_to_en = f1.readlines()\n\nwith open('/kaggle/input/chatgptfiles/ta_to_hi.txt', 'r') as f1:\n    ta_to_hi = f1.readlines()\n    \nwith open('/kaggle/input/chatgptfiles/hi_to_ta.txt', 'r') as f1:\n    hi_to_ta = f1.readlines()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:05:54.190806Z","iopub.execute_input":"2024-04-17T16:05:54.191368Z","iopub.status.idle":"2024-04-17T16:05:54.258483Z","shell.execute_reply.started":"2024-04-17T16:05:54.191338Z","shell.execute_reply":"2024-04-17T16:05:54.257273Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## BLEU SCORE","metadata":{}},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:05:58.335325Z","iopub.execute_input":"2024-04-17T16:05:58.335688Z","iopub.status.idle":"2024-04-17T16:06:00.223405Z","shell.execute_reply.started":"2024-04-17T16:05:58.335659Z","shell.execute_reply":"2024-04-17T16:06:00.222464Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"bleu_score = corpus_bleu(en, hi_to_en)\nprint(\"BLEU SCORE FOR HINDI TO ENGLISH: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:06:01.467335Z","iopub.execute_input":"2024-04-17T16:06:01.468066Z","iopub.status.idle":"2024-04-17T16:06:02.385271Z","shell.execute_reply.started":"2024-04-17T16:06:01.468035Z","shell.execute_reply":"2024-04-17T16:06:02.384154Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR HINDI TO ENGLISH:  0.6839972692624341\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(hi, en_to_hi)\nprint(\"BLEU SCORE FOR ENGLISH TO HINDI: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:06:13.111392Z","iopub.execute_input":"2024-04-17T16:06:13.111860Z","iopub.status.idle":"2024-04-17T16:06:13.946807Z","shell.execute_reply.started":"2024-04-17T16:06:13.111831Z","shell.execute_reply":"2024-04-17T16:06:13.945587Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR ENGLISH TO HINDI:  0.7388852243229926\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(hi, ta_to_hi)\nprint(\"BLEU SCORE FOR TAMIL TO HINDI: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:06:24.702910Z","iopub.execute_input":"2024-04-17T16:06:24.703853Z","iopub.status.idle":"2024-04-17T16:06:25.583031Z","shell.execute_reply.started":"2024-04-17T16:06:24.703818Z","shell.execute_reply":"2024-04-17T16:06:25.582045Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR TAMIL TO HINDI:  0.7065366009396985\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(ta, hi_to_ta)\nprint(\"BLEU SCORE FOR HINDI TO TAMIL: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:06:44.870908Z","iopub.execute_input":"2024-04-17T16:06:44.871587Z","iopub.status.idle":"2024-04-17T16:06:45.915909Z","shell.execute_reply.started":"2024-04-17T16:06:44.871533Z","shell.execute_reply":"2024-04-17T16:06:45.914949Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR HINDI TO TAMIL:  0.6777784162282268\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ROUGE SCORE","metadata":{}},{"cell_type":"code","source":"!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:20:43.718428Z","iopub.execute_input":"2024-04-17T08:20:43.718910Z","iopub.status.idle":"2024-04-17T08:21:00.509389Z","shell.execute_reply.started":"2024-04-17T08:20:43.718874Z","shell.execute_reply":"2024-04-17T08:21:00.508027Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge import Rouge\nrouge = Rouge()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:21:20.360635Z","iopub.execute_input":"2024-04-17T08:21:20.361117Z","iopub.status.idle":"2024-04-17T08:21:20.373047Z","shell.execute_reply.started":"2024-04-17T08:21:20.361081Z","shell.execute_reply":"2024-04-17T08:21:20.371684Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"scores = rouge.get_scores(hi_to_en, en, avg=True)\nprint(\"ROUGE SCORE FOR HINDI TO ENGLISH: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:21:39.349222Z","iopub.execute_input":"2024-04-17T08:21:39.350495Z","iopub.status.idle":"2024-04-17T08:21:39.397054Z","shell.execute_reply.started":"2024-04-17T08:21:39.350453Z","shell.execute_reply":"2024-04-17T08:21:39.395606Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR HINDI TO ENGLISH: \nrouge-1 : {'r': 0.6254789760296852, 'p': 0.6032089890636129, 'f': 0.6109201698422649}\nrouge-2 : {'r': 0.36539111751382586, 'p': 0.35719844675747225, 'f': 0.3589186585052161}\nrouge-l : {'r': 0.5906476530902028, 'p': 0.5704852295095262, 'f': 0.577321572941242}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(en_to_hi, hi, avg=True)\nprint(\"ROUGE SCORE FOR ENGLISH TO HINDI: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:21:48.138338Z","iopub.execute_input":"2024-04-17T08:21:48.138748Z","iopub.status.idle":"2024-04-17T08:21:48.185246Z","shell.execute_reply.started":"2024-04-17T08:21:48.138719Z","shell.execute_reply":"2024-04-17T08:21:48.183992Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR ENGLISH TO HINDI: \nrouge-1 : {'r': 0.6105420708369763, 'p': 0.6093202485633499, 'f': 0.6076019185911911}\nrouge-2 : {'r': 0.3855576484205134, 'p': 0.38642045782705, 'f': 0.3849238519216449}\nrouge-l : {'r': 0.5832642974121441, 'p': 0.583596030401051, 'f': 0.5811938292988912}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(ta_to_hi, hi, avg=True)\nprint(\"ROUGE SCORE FOR TAMIL TO HINDI: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:21:56.440725Z","iopub.execute_input":"2024-04-17T08:21:56.441102Z","iopub.status.idle":"2024-04-17T08:21:56.486001Z","shell.execute_reply.started":"2024-04-17T08:21:56.441075Z","shell.execute_reply":"2024-04-17T08:21:56.484754Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR TAMIL TO HINDI: \nrouge-1 : {'r': 0.3275244229554795, 'p': 0.3253921889196102, 'f': 0.3224311220081945}\nrouge-2 : {'r': 0.14046024040907268, 'p': 0.14439530080905652, 'f': 0.1410619701321918}\nrouge-l : {'r': 0.28909854677564406, 'p': 0.2882438905323362, 'f': 0.2851819850449647}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(hi_to_ta, ta, avg=True)\nprint(\"ROUGE SCORE FOR HINDI TO TAMIL: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T08:22:06.938222Z","iopub.execute_input":"2024-04-17T08:22:06.939366Z","iopub.status.idle":"2024-04-17T08:22:06.980573Z","shell.execute_reply.started":"2024-04-17T08:22:06.939312Z","shell.execute_reply":"2024-04-17T08:22:06.979456Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR HINDI TO TAMIL: \nrouge-1 : {'r': 0.22646200983873133, 'p': 0.2283529425481224, 'f': 0.22353704572359345}\nrouge-2 : {'r': 0.03909365634365634, 'p': 0.040500721500721495, 'f': 0.03902279027456767}\nrouge-l : {'r': 0.2136894213161428, 'p': 0.21570128048469558, 'f': 0.21097702353688458}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}