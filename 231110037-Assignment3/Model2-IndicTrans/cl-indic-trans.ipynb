{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8123924,"sourceType":"datasetVersion","datasetId":4800723},{"sourceId":8136248,"sourceType":"datasetVersion","datasetId":4809761},{"sourceId":8138542,"sourceType":"datasetVersion","datasetId":4811444}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:08:48.359751Z","iopub.execute_input":"2024-04-16T13:08:48.360064Z","iopub.status.idle":"2024-04-16T13:08:48.375010Z","shell.execute_reply.started":"2024-04-16T13:08:48.360039Z","shell.execute_reply":"2024-04-16T13:08:48.374121Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/VarunGumma/IndicTransTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:08:48.560543Z","iopub.execute_input":"2024-04-16T13:08:48.560851Z","iopub.status.idle":"2024-04-16T13:08:50.742203Z","shell.execute_reply.started":"2024-04-16T13:08:48.560805Z","shell.execute_reply":"2024-04-16T13:08:50.741126Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'IndicTransTokenizer'...\nremote: Enumerating objects: 123, done.\u001b[K\nremote: Counting objects: 100% (123/123), done.\u001b[K\nremote: Compressing objects: 100% (80/80), done.\u001b[K\nremote: Total 123 (delta 52), reused 94 (delta 31), pack-reused 0\u001b[K\nReceiving objects: 100% (123/123), 3.85 MiB | 15.72 MiB/s, done.\nResolving deltas: 100% (52/52), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/IndicTransTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:08:50.744446Z","iopub.execute_input":"2024-04-16T13:08:50.744757Z","iopub.status.idle":"2024-04-16T13:08:50.752399Z","shell.execute_reply.started":"2024-04-16T13:08:50.744729Z","shell.execute_reply":"2024-04-16T13:08:50.751229Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/IndicTransTokenizer\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --editable ./","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:08:50.753877Z","iopub.execute_input":"2024-04-16T13:08:50.754527Z","iopub.status.idle":"2024-04-16T13:09:28.562864Z","shell.execute_reply.started":"2024-04-16T13:08:50.754490Z","shell.execute_reply":"2024-04-16T13:09:28.561759Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/IndicTransTokenizer\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library (from IndicTransTokenizer==0.1.3)\n  Cloning https://github.com/VarunGumma/indic_nlp_library to /tmp/pip-install-p44fobw9/indic-nlp-library-it2_964d394ed49f4eceabad4700940e3679\n  Running command git clone --filter=blob:none --quiet https://github.com/VarunGumma/indic_nlp_library /tmp/pip-install-p44fobw9/indic-nlp-library-it2_964d394ed49f4eceabad4700940e3679\n  Resolved https://github.com/VarunGumma/indic_nlp_library to commit 09d30a15286cc252a12682e5450c807379717eaf\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting setuptools==68.2.2 (from IndicTransTokenizer==0.1.3)\n  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (2.1.2)\nCollecting sacremoses (from IndicTransTokenizer==0.1.3)\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (0.2.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from IndicTransTokenizer==0.1.3) (4.39.3)\nCollecting sacrebleu==2.3.1 (from IndicTransTokenizer==0.1.3)\n  Downloading sacrebleu-2.3.1-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m931.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu==2.3.1->IndicTransTokenizer==0.1.3) (5.2.1)\nCollecting sphinx-argparse (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinx_argparse-0.4.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: sphinx_rtd_theme in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.2.4)\nCollecting morfessor (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.1.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (1.3.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses->IndicTransTokenizer==0.1.3) (4.66.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->IndicTransTokenizer==0.1.3) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->IndicTransTokenizer==0.1.3) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->IndicTransTokenizer==0.1.3) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->IndicTransTokenizer==0.1.3) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->IndicTransTokenizer==0.1.3) (2024.2.2)\nCollecting sphinx>=1.2.0 (from sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->IndicTransTokenizer==0.1.3) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (1.16.0)\nCollecting sphinxcontrib-applehelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-devhelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-jsmath (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\nCollecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\nCollecting sphinxcontrib-qthelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.17.2)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3) (2.14.0)\nCollecting alabaster<0.8,>=0.7 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\nCollecting imagesize>=1.3 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library-IT2@ git+https://github.com/VarunGumma/indic_nlp_library->IndicTransTokenizer==0.1.3)\n  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\nDownloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nDownloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\nDownloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\nDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\nDownloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\nDownloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: indic-nlp-library-IT2\n  Building wheel for indic-nlp-library-IT2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for indic-nlp-library-IT2: filename=indic_nlp_library_IT2-0.0.2-py3-none-any.whl size=49537 sha256=e1a4557c582cf5c139fb5f200730a458e58c4b5031ead16a4eed3e7d61fee8b9\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3flgvr9h/wheels/e9/72/fa/bd9f19a3f2bacb50efcaf28b7ab89fe7ca539e35b75334befc\nSuccessfully built indic-nlp-library-IT2\nInstalling collected packages: morfessor, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, setuptools, sacremoses, portalocker, imagesize, alabaster, sphinx, sacrebleu, sphinx-argparse, indic-nlp-library-IT2, IndicTransTokenizer\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 69.0.3\n    Uninstalling setuptools-69.0.3:\n      Successfully uninstalled setuptools-69.0.3\n  Running setup.py develop for IndicTransTokenizer\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed IndicTransTokenizer-0.1.3 alabaster-0.7.16 imagesize-1.4.1 indic-nlp-library-IT2-0.0.2 morfessor-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1 sacremoses-0.1.1 setuptools-68.2.2 sphinx-7.2.6 sphinx-argparse-0.4.0 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSeq2SeqLM\nfrom IndicTransTokenizer import IndicProcessor, IndicTransTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:09:37.148565Z","iopub.execute_input":"2024-04-16T13:09:37.149603Z","iopub.status.idle":"2024-04-16T13:09:45.216387Z","shell.execute_reply.started":"2024-04-16T13:09:37.149551Z","shell.execute_reply":"2024-04-16T13:09:45.215632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## SELECT RANDOM 1000 LINES","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/selected/enselected.txt', 'r') as f1:\n    selected_en = f1.readlines()\n    \nwith open('/kaggle/input/selected/hiselected.txt', 'r') as f1:\n    selected_hi = f1.readlines()\n    \nwith open('/kaggle/input/selected/taselected.txt', 'r') as f1:\n    selected_ta = f1.readlines()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:10:15.769059Z","iopub.execute_input":"2024-04-16T13:10:15.769586Z","iopub.status.idle":"2024-04-16T13:10:15.803306Z","shell.execute_reply.started":"2024-04-16T13:10:15.769556Z","shell.execute_reply":"2024-04-16T13:10:15.802367Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## ENGLISH TO HINDI ","metadata":{}},{"cell_type":"code","source":"tokenizer = IndicTransTokenizer(direction=\"en-indic\")\nip = IndicProcessor(inference=True)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True,low_cpu_mem_usage=True).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:13:01.559715Z","iopub.execute_input":"2024-04-16T13:13:01.560090Z","iopub.status.idle":"2024-04-16T13:13:10.322265Z","shell.execute_reply.started":"2024-04-16T13:13:01.560062Z","shell.execute_reply":"2024-04-16T13:13:10.321388Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177acbd186e44f16b78932160bef1e18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c026b9fbf684074b46a3963021fecc4"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9357ccc98f7b405c91174a460aa4406e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f5b332b79d844a1bd64bdf6fd9c866a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd25954c5b046d79e3cc5b8bb776038"}},"metadata":{}}]},{"cell_type":"code","source":"answers = []\nBATCH_SIZE = 4\nfor i in range(0,len(selected_en),BATCH_SIZE):\n    batch = selected_en[i : i + BATCH_SIZE]\n\n    # Preprocess the batch and extract entity mappings\n    batch = ip.preprocess_batch(batch, src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\")\n\n    # Tokenize the batch and generate input encodings\n    batch = tokenizer(batch, src=True, return_tensors=\"pt\").to(\"cuda\")\n\n    with torch.inference_mode():\n        outputs = model.generate(**batch,use_cache=True, num_beams=5, num_return_sequences=1, max_length=256)\n\n    # Decode the generated tokens into text\n    outputs = tokenizer.batch_decode(outputs, src=False)\n\n    # Postprocess the translations, including entity replacement\n    outputs = ip.postprocess_batch(outputs, lang=\"hin_Deva\")\n    answers.append(outputs)\n    del batch\n    torch.cuda.empty_cache()\nprint(len(answers))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:13:24.868206Z","iopub.execute_input":"2024-04-16T13:13:24.868556Z","iopub.status.idle":"2024-04-16T13:16:21.627544Z","shell.execute_reply.started":"2024-04-16T13:13:24.868530Z","shell.execute_reply":"2024-04-16T13:16:21.626588Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"250\n","output_type":"stream"}]},{"cell_type":"code","source":"output_file = '/kaggle/working/ITen_to_hi.txt'\nwith open(output_file, 'w') as f:\n    for lst in answers:\n        for line in lst:\n            f.write(line+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:35:51.724740Z","iopub.execute_input":"2024-04-16T13:35:51.725165Z","iopub.status.idle":"2024-04-16T13:35:51.732181Z","shell.execute_reply.started":"2024-04-16T13:35:51.725135Z","shell.execute_reply":"2024-04-16T13:35:51.731300Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## HINDI TO ENGLISH","metadata":{}},{"cell_type":"code","source":"tokenizer = IndicTransTokenizer(direction=\"indic-en\")\nip = IndicProcessor(inference=True)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-en-dist-200M\", trust_remote_code=True, low_cpu_mem_usage=True).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:38:15.207917Z","iopub.execute_input":"2024-04-16T13:38:15.208322Z","iopub.status.idle":"2024-04-16T13:38:21.035398Z","shell.execute_reply.started":"2024-04-16T13:38:15.208294Z","shell.execute_reply":"2024-04-16T13:38:21.034542Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6efaf0a23a59437ab206d5699c0a04de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef41e857991444e29ecce968b16d2d27"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11a198ec1fc84302ab15ee3c3a910cde"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-en-dist-200M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/914M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b9e1d7af81442194178ce8dc669b3a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177153a842414990a3d9f341ffa8317f"}},"metadata":{}}]},{"cell_type":"code","source":"answers = []\nBATCH_SIZE = 4\nfor i in range(0,len(selected_hi),BATCH_SIZE):\n    batch = selected_hi[i : i + BATCH_SIZE]\n\n    # Preprocess the batch and extract entity mappings\n    batch = ip.preprocess_batch(batch, src_lang=\"hin_Deva\", tgt_lang=\"eng_Latn\")\n\n    # Tokenize the batch and generate input encodings\n    batch = tokenizer(batch, src=True, return_tensors=\"pt\").to(\"cuda\")\n\n    with torch.inference_mode():\n        outputs = model.generate(**batch,use_cache=True, num_beams=5, num_return_sequences=1, max_length=256)\n\n    # Decode the generated tokens into text\n    outputs = tokenizer.batch_decode(outputs, src=False)\n\n    # Postprocess the translations, including entity replacement\n    outputs = ip.postprocess_batch(outputs, lang=\"eng_Latn\")\n    answers.append(outputs)\n    del batch\n    torch.cuda.empty_cache()\nprint(len(answers))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:41:53.435172Z","iopub.execute_input":"2024-04-16T13:41:53.435555Z","iopub.status.idle":"2024-04-16T13:44:27.223150Z","shell.execute_reply.started":"2024-04-16T13:41:53.435525Z","shell.execute_reply":"2024-04-16T13:44:27.222063Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"250\n","output_type":"stream"}]},{"cell_type":"code","source":"output_file = '/kaggle/working/IThi_to_en.txt'\nwith open(output_file, 'w') as f:\n    for lst in answers:\n        for line in lst:\n            f.write(line+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:44:51.108635Z","iopub.execute_input":"2024-04-16T13:44:51.109617Z","iopub.status.idle":"2024-04-16T13:44:51.115750Z","shell.execute_reply.started":"2024-04-16T13:44:51.109581Z","shell.execute_reply":"2024-04-16T13:44:51.114758Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## TAMIL TO HINDI","metadata":{}},{"cell_type":"code","source":"tokenizer = IndicTransTokenizer(direction=\"indic-indic\")\nip = IndicProcessor(inference=True)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-indic-dist-320M\", trust_remote_code=True, low_cpu_mem_usage=True).to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:45:55.527148Z","iopub.execute_input":"2024-04-16T13:45:55.527811Z","iopub.status.idle":"2024-04-16T13:46:04.060604Z","shell.execute_reply.started":"2024-04-16T13:45:55.527775Z","shell.execute_reply":"2024-04-16T13:46:04.059699Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a280ff126974f6782fdf68819ab8110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e35343be148547199301af78b793a62e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bad5f5bf0863441a828b8cf826ccc4cb"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c391abbef75461e9c864fbf36ce53eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85afe29169ca43e2ac3e4b124586fb7c"}},"metadata":{}}]},{"cell_type":"code","source":"answers = []\nBATCH_SIZE = 4\nfor i in range(0,len(selected_ta),BATCH_SIZE):\n    batch = selected_ta[i : i + BATCH_SIZE]\n\n    # Preprocess the batch and extract entity mappings\n    batch = ip.preprocess_batch(batch, src_lang=\"tam_Taml\", tgt_lang=\"hin_Deva\")\n\n    # Tokenize the batch and generate input encodings\n    batch = tokenizer(batch, src=True, return_tensors=\"pt\").to(\"cuda\")\n\n    with torch.inference_mode():\n        outputs = model.generate(**batch,use_cache=True, num_beams=5, num_return_sequences=1, max_length=256)\n\n    # Decode the generated tokens into text\n    outputs = tokenizer.batch_decode(outputs, src=False)\n\n    # Postprocess the translations, including entity replacement\n    outputs = ip.postprocess_batch(outputs, lang=\"hin_Deva\")\n    answers.append(outputs)\n    del batch\n    torch.cuda.empty_cache()\nprint(len(answers))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:46:23.274541Z","iopub.execute_input":"2024-04-16T13:46:23.275212Z","iopub.status.idle":"2024-04-16T13:49:12.254646Z","shell.execute_reply.started":"2024-04-16T13:46:23.275177Z","shell.execute_reply":"2024-04-16T13:49:12.253488Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"250\n","output_type":"stream"}]},{"cell_type":"code","source":"output_file = '/kaggle/working/ITta_to_hi.txt'\nwith open(output_file, 'w') as f:\n    for lst in answers:\n        for line in lst:\n            f.write(line+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:50:05.344988Z","iopub.execute_input":"2024-04-16T13:50:05.345693Z","iopub.status.idle":"2024-04-16T13:50:05.352551Z","shell.execute_reply.started":"2024-04-16T13:50:05.345653Z","shell.execute_reply":"2024-04-16T13:50:05.351635Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## HINDI TO TAMIL","metadata":{}},{"cell_type":"code","source":"answers = []\nBATCH_SIZE = 4\nfor i in range(0,len(selected_hi),BATCH_SIZE):\n    batch = selected_hi[i : i + BATCH_SIZE]\n\n    # Preprocess the batch and extract entity mappings\n    batch = ip.preprocess_batch(batch, src_lang=\"hin_Deva\", tgt_lang=\"tam_Taml\")\n\n    # Tokenize the batch and generate input encodings\n    batch = tokenizer(batch, src=True, return_tensors=\"pt\").to(\"cuda\")\n\n    with torch.inference_mode():\n        outputs = model.generate(**batch,use_cache=True, num_beams=5, num_return_sequences=1, max_length=256)\n\n    # Decode the generated tokens into text\n    outputs = tokenizer.batch_decode(outputs, src=False)\n\n    # Postprocess the translations, including entity replacement\n    outputs = ip.postprocess_batch(outputs, lang=\"tam_Taml\")\n    answers.append(outputs)\n    del batch\n    torch.cuda.empty_cache()\nprint(len(answers))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:50:42.785966Z","iopub.execute_input":"2024-04-16T13:50:42.787288Z","iopub.status.idle":"2024-04-16T13:53:40.280577Z","shell.execute_reply.started":"2024-04-16T13:50:42.787247Z","shell.execute_reply":"2024-04-16T13:53:40.279596Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"250\n","output_type":"stream"}]},{"cell_type":"code","source":"output_file = '/kaggle/working/IThi_to_ta.txt'\nwith open(output_file, 'w') as f:\n    for lst in answers:\n        for line in lst:\n            f.write(line+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T13:54:34.501352Z","iopub.execute_input":"2024-04-16T13:54:34.502049Z","iopub.status.idle":"2024-04-16T13:54:34.508687Z","shell.execute_reply.started":"2024-04-16T13:54:34.502014Z","shell.execute_reply":"2024-04-16T13:54:34.507875Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## BLEU SCORE","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/selected/enselected.txt', 'r') as f1:\n    en = f1.readlines()\n\nwith open('/kaggle/input/selected/hiselected.txt', 'r') as f2:\n    hi = f2.readlines()\n\nwith open('/kaggle/input/selected/taselected.txt', 'r') as f2:\n    ta = f2.readlines()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:03:40.101534Z","iopub.execute_input":"2024-04-17T16:03:40.102399Z","iopub.status.idle":"2024-04-17T16:03:40.211706Z","shell.execute_reply.started":"2024-04-17T16:03:40.102364Z","shell.execute_reply":"2024-04-17T16:03:40.210709Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/outputs/ITen_to_hi.txt', 'r') as f1:\n    en_to_hi = f1.readlines()\n    \nwith open('/kaggle/input/outputs/IThi_to_en.txt', 'r') as f1:\n    hi_to_en = f1.readlines()\n\nwith open('/kaggle/input/outputs/ITta_to_hi.txt', 'r') as f1:\n    ta_to_hi = f1.readlines()\n    \nwith open('/kaggle/input/outputs/IThi_to_ta.txt', 'r') as f1:\n    hi_to_ta = f1.readlines()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:03:42.168318Z","iopub.execute_input":"2024-04-17T16:03:42.169319Z","iopub.status.idle":"2024-04-17T16:03:42.256735Z","shell.execute_reply.started":"2024-04-17T16:03:42.169283Z","shell.execute_reply":"2024-04-17T16:03:42.255691Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:03:52.560349Z","iopub.execute_input":"2024-04-17T16:03:52.561149Z","iopub.status.idle":"2024-04-17T16:03:55.741983Z","shell.execute_reply.started":"2024-04-17T16:03:52.561114Z","shell.execute_reply":"2024-04-17T16:03:55.741041Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"bleu_score = corpus_bleu(en[:50], hi_to_en[:50])\nprint(\"BLEU SCORE FOR HINDI TO ENGLISH: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:04:05.628835Z","iopub.execute_input":"2024-04-17T16:04:05.629800Z","iopub.status.idle":"2024-04-17T16:04:06.728913Z","shell.execute_reply.started":"2024-04-17T16:04:05.629766Z","shell.execute_reply":"2024-04-17T16:04:06.727983Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR HINDI TO ENGLISH:  0.6946380319226029\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(hi[:50], en_to_hi[:50])\nprint(\"BLEU SCORE FOR ENGLISH TO HINDI: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:04:21.495107Z","iopub.execute_input":"2024-04-17T16:04:21.495789Z","iopub.status.idle":"2024-04-17T16:04:22.499471Z","shell.execute_reply.started":"2024-04-17T16:04:21.495754Z","shell.execute_reply":"2024-04-17T16:04:22.498436Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR ENGLISH TO HINDI:  0.7393176589394633\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(hi[:50], ta_to_hi[:50])\nprint(\"BLEU SCORE FOR TAMIL TO HINDI: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:04:36.772975Z","iopub.execute_input":"2024-04-17T16:04:36.773670Z","iopub.status.idle":"2024-04-17T16:04:37.744627Z","shell.execute_reply.started":"2024-04-17T16:04:36.773619Z","shell.execute_reply":"2024-04-17T16:04:37.743704Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR TAMIL TO HINDI:  0.729996495977605\n","output_type":"stream"}]},{"cell_type":"code","source":"bleu_score = corpus_bleu(ta[:50], hi_to_ta[:50])\nprint(\"BLEU SCORE FOR HINDI TO TAMIL: \",bleu_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:04:44.027418Z","iopub.execute_input":"2024-04-17T16:04:44.028368Z","iopub.status.idle":"2024-04-17T16:04:45.299347Z","shell.execute_reply.started":"2024-04-17T16:04:44.028331Z","shell.execute_reply":"2024-04-17T16:04:45.298404Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"BLEU SCORE FOR HINDI TO TAMIL:  0.6928307685071132\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ROUGE SCORE","metadata":{}},{"cell_type":"code","source":"!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:06.166907Z","iopub.execute_input":"2024-04-17T13:33:06.167879Z","iopub.status.idle":"2024-04-17T13:33:19.452153Z","shell.execute_reply.started":"2024-04-17T13:33:06.167845Z","shell.execute_reply":"2024-04-17T13:33:19.450993Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge import Rouge\nrouge = Rouge()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:19.454230Z","iopub.execute_input":"2024-04-17T13:33:19.454549Z","iopub.status.idle":"2024-04-17T13:33:19.463461Z","shell.execute_reply.started":"2024-04-17T13:33:19.454518Z","shell.execute_reply":"2024-04-17T13:33:19.462717Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"scores = rouge.get_scores(hi_to_en[:50], en[:50], avg=True)\nprint(\"ROUGE SCORE FOR HINDI TO ENGLISH: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:31.984264Z","iopub.execute_input":"2024-04-17T13:33:31.984625Z","iopub.status.idle":"2024-04-17T13:33:32.021133Z","shell.execute_reply.started":"2024-04-17T13:33:31.984597Z","shell.execute_reply":"2024-04-17T13:33:32.020164Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR HINDI TO ENGLISH: \nrouge-1 : {'r': 0.6611118471653776, 'p': 0.6520790173832468, 'f': 0.6531700197799464}\nrouge-2 : {'r': 0.4205068189613888, 'p': 0.4193624139560719, 'f': 0.4173564109556508}\nrouge-l : {'r': 0.6260610716086846, 'p': 0.6166978733038269, 'f': 0.6181932888088356}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(en_to_hi[:50], hi[:50], avg=True)\nprint(\"ROUGE SCORE FOR ENGLISH TO HINDI: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:40.925241Z","iopub.execute_input":"2024-04-17T13:33:40.925854Z","iopub.status.idle":"2024-04-17T13:33:40.959598Z","shell.execute_reply.started":"2024-04-17T13:33:40.925821Z","shell.execute_reply":"2024-04-17T13:33:40.958624Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR ENGLISH TO HINDI: \nrouge-1 : {'r': 0.5895219500982772, 'p': 0.5909189053298693, 'f': 0.5870490708000117}\nrouge-2 : {'r': 0.34807683542135004, 'p': 0.35522161759378307, 'f': 0.3494625915233706}\nrouge-l : {'r': 0.5529000755287315, 'p': 0.555578366927625, 'f': 0.5512373093550673}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(ta_to_hi[:50], hi[:50], avg=True)\nprint(\"ROUGE SCORE FOR TAMIL TO HINDI: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:49.791889Z","iopub.execute_input":"2024-04-17T13:33:49.792741Z","iopub.status.idle":"2024-04-17T13:33:49.826252Z","shell.execute_reply.started":"2024-04-17T13:33:49.792709Z","shell.execute_reply":"2024-04-17T13:33:49.825298Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR TAMIL TO HINDI: \nrouge-1 : {'r': 0.44568356454458813, 'p': 0.4424566099149152, 'f': 0.43982184817519515}\nrouge-2 : {'r': 0.2108982417572706, 'p': 0.2109436988595825, 'f': 0.20848058396385358}\nrouge-l : {'r': 0.40959540379466264, 'p': 0.4089512651876024, 'f': 0.40550507700485044}\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = rouge.get_scores(hi_to_ta[:50], ta[:50], avg=True)\nprint(\"ROUGE SCORE FOR HINDI TO TAMIL: \")\nfor key,value in scores.items():\n    print(key, \":\" ,value)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T13:33:57.636201Z","iopub.execute_input":"2024-04-17T13:33:57.636873Z","iopub.status.idle":"2024-04-17T13:33:57.663344Z","shell.execute_reply.started":"2024-04-17T13:33:57.636843Z","shell.execute_reply":"2024-04-17T13:33:57.662512Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"ROUGE SCORE FOR HINDI TO TAMIL: \nrouge-1 : {'r': 0.4002495094084237, 'p': 0.4054384804409033, 'f': 0.3995532037804487}\nrouge-2 : {'r': 0.1506372714832467, 'p': 0.14701055537244795, 'f': 0.14767167917612337}\nrouge-l : {'r': 0.3814232407931084, 'p': 0.38509125456736176, 'f': 0.38019024751203057}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}